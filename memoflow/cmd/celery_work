#!/usr/bin/python3
import os
import sys
from multiprocessing import Process
from celery.signals import worker_process_init
# 获取当前文件的目录
current_dir = os.path.dirname(os.path.abspath(__file__))
top_dir = os.path.dirname(os.path.dirname(current_dir))
# 将工作目录更改为当前文件的目录
os.chdir(top_dir)
sys.path.insert(0,top_dir)

from memoflow.conf import CONF
from memoflow.core import log_util
from memoflow.core.ConfigParse import ConfigParse
from memoflow.tasks import celery_task

# 配置日志，但好像work进程的日志还是没有打印在指定的文件中
cp = ConfigParse(CONF.server['server_conf_path'])
cf_defaults = cp.read_file().get("default")

@worker_process_init.connect
def configure_logging(**kwargs):
    # logging.config.fileConfig('logging.ini')
    log_util.server_setup(cf_defaults.get("celery_log_file"),'celery')

app = celery_task.celery

# 异步任务
def start_worker():
    app.worker_main(argv=['worker', '-l', 'info',
                          '-f', cf_defaults.get("celery_log_file")])

# 定时任务
def start_beat():
    beat = app.Beat(loglevel='info', logfile=cf_defaults.get("celery_log_file"))
    beat.run()

if __name__ == "__main__":
    # === 确保日志目录存在 ===
    log_file = cf_defaults.get("celery_log_file")
    log_dir = os.path.dirname(log_file)
    os.makedirs(log_dir, exist_ok=True)
    worker_process = Process(target=start_worker)
    beat_process = Process(target=start_beat)
    worker_process.start()
    beat_process.start()
    worker_process.join()
    beat_process.join()
